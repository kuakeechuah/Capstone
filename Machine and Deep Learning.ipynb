{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkc3\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\kkc3\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\kkc3\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\kkc3\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\kkc3\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\kkc3\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\kkc3\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\kkc3\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\kkc3\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\kkc3\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\kkc3\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\kkc3\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Libraries for classical machine learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Libraries for deep learning\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Flatten, Embedding, Dropout, Bidirectional, SpatialDropout1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Libraries for topic modeling\n",
    "from pprint import pprint\n",
    "import gensim, spacy\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "from nltk.corpus import stopwords\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = pd.read_csv('./datasets/clean_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>username</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_clean</th>\n",
       "      <th>number_of_words</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132</td>\n",
       "      <td>IluvatarIrmo</td>\n",
       "      <td>7.0</td>\n",
       "      <td>beautiful miniatures. Gameplay is random due t...</td>\n",
       "      <td>beautiful miniature gameplay random due dice t...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1773</td>\n",
       "      <td>Rabid</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Freakin' awesome!\\nSimple rules, smooth gamepl...</td>\n",
       "      <td>freakin awesome simple rule smooth gameplay ni...</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2492</td>\n",
       "      <td>LouieSTFU</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Expansions:\\n[thing=174506][/thing]</td>\n",
       "      <td>expansion thing thing</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1962</td>\n",
       "      <td>terp8in</td>\n",
       "      <td>9.0</td>\n",
       "      <td>After single play, I like this very much.  How...</td>\n",
       "      <td>single play like much however game play need p...</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1769</td>\n",
       "      <td>Quertzacoalt</td>\n",
       "      <td>6.0</td>\n",
       "      <td>You probably heard that before, but this game ...</td>\n",
       "      <td>probably heard game broken player way easy sur...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      username  rating  \\\n",
       "0         132  IluvatarIrmo     7.0   \n",
       "1        1773         Rabid     9.0   \n",
       "2        2492     LouieSTFU     8.0   \n",
       "3        1962       terp8in     9.0   \n",
       "4        1769  Quertzacoalt     6.0   \n",
       "\n",
       "                                             comment  \\\n",
       "0  beautiful miniatures. Gameplay is random due t...   \n",
       "1  Freakin' awesome!\\nSimple rules, smooth gamepl...   \n",
       "2                Expansions:\\n[thing=174506][/thing]   \n",
       "3  After single play, I like this very much.  How...   \n",
       "4  You probably heard that before, but this game ...   \n",
       "\n",
       "                                       comment_clean  number_of_words  target  \n",
       "0  beautiful miniature gameplay random due dice t...                9       1  \n",
       "1  freakin awesome simple rule smooth gameplay ni...               24       1  \n",
       "2                              expansion thing thing                3       1  \n",
       "3  single play like much however game play need p...               25       1  \n",
       "4  probably heard game broken player way easy sur...               18       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13268, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment.shape #13,259 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.755803\n",
       "0    0.244197\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline score\n",
    "comment['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = comment['comment_clean']\n",
    "y = comment['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10614,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2654,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.755794\n",
       "0    0.244206\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.75584\n",
       "0    0.24416\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10614, 17082)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use count vectorizer to check how many unique words there are\n",
    "cvec = CountVectorizer(stop_words='english') \n",
    "cvec_df = pd.DataFrame(cvec.fit_transform(X_train).todense(), columns=cvec.get_feature_names())\n",
    "cvec_df.shape #17878 unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that takes in the actual y value and model predictions, \n",
    "# and prints out the confusion matrix and classification report\n",
    "# Dataset: Validation or test set\n",
    "\n",
    "def cmat(actual_y, predictions, dataset):\n",
    "    \n",
    "    # Create a classification report\n",
    "    print('Classification report for', dataset)\n",
    "    print(classification_report(actual_y, predictions))\n",
    "    print('')\n",
    "    \n",
    "    # Create a confusion matrix\n",
    "    cm = confusion_matrix(actual_y, predictions)\n",
    "    cm_df = pd.DataFrame(cm, columns=['Predicted Positive Review','Predicted Negative Review'], index=['Actual Positive Review', 'Actual Negative Review'])\n",
    "    print('Confusion matrix for', dataset)\n",
    "    print(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count vectorizer & logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'cvec__max_df': 0.9, 'cvec__max_features': 300, 'cvec__min_df': 2, 'lr__C': 0.1, 'lr__penalty': 'l2'}\n",
      "Best CV score:  0.7724734686922581\n",
      "Training score: 0.7829282080271339\n",
      "Validation score: 0.7709118311981914\n",
      "\n",
      "Classification report for validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.16      0.25       648\n",
      "           1       0.78      0.97      0.86      2006\n",
      "\n",
      "    accuracy                           0.77      2654\n",
      "   macro avg       0.70      0.56      0.56      2654\n",
      "weighted avg       0.74      0.77      0.71      2654\n",
      "\n",
      "\n",
      "Confusion matrix for validation set\n",
      "                        Predicted Positive Review  Predicted Negative Review\n",
      "Actual Positive Review                        101                        547\n",
      "Actual Negative Review                         61                       1945\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with Count Vectorizer and Logistic Regression\n",
    "pipe_cvec_lr = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words='english')), \n",
    "    ('lr', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "pipe_cvec_lr_params = {\n",
    "    'cvec__max_features': [300], #100,200\n",
    "    'cvec__min_df': [2,3], \n",
    "    'cvec__max_df': [.9,.95], \n",
    "#     'cvec__ngram_range':[(1,1),(1,2)],  \n",
    "    'lr__penalty': ['l2'],\n",
    "    'lr__C': [.01,.1]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "gs_cvec_lr = GridSearchCV(pipe_cvec_lr, # Objects to optimise\n",
    "                          param_grid = pipe_cvec_lr_params, # Hyperparameters for tuning\n",
    "                          cv=10) # 10-fold cross validation\n",
    "\n",
    "# Fit model on to training data\n",
    "gs_cvec_lr.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions on validation set\n",
    "cvec_lr_pred = gs_cvec_lr.predict(X_val)\n",
    "\n",
    "# Print best parameters\n",
    "print('Best parameters: ', gs_cvec_lr.best_params_)\n",
    "\n",
    "# Print accuracy scores\n",
    "print('Best CV score: ', gs_cvec_lr.best_score_)\n",
    "print('Training score:', gs_cvec_lr.score(X_train, y_train))\n",
    "print('Validation score:', gs_cvec_lr.score(X_val, y_val))\n",
    "print('')\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "cmat(y_val, cvec_lr_pred, 'validation set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf & logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'lr__C': 1, 'lr__penalty': 'l2', 'tvec__max_df': 0.9, 'tvec__max_features': 300, 'tvec__min_df': 2}\n",
      "Best CV score:  0.7755803695834687\n",
      "Training score: 0.7860373092142453\n",
      "Validation score: 0.7720422004521477\n",
      "\n",
      "Classification report for validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.17      0.26       648\n",
      "           1       0.78      0.97      0.87      2006\n",
      "\n",
      "    accuracy                           0.77      2654\n",
      "   macro avg       0.70      0.57      0.56      2654\n",
      "weighted avg       0.74      0.77      0.72      2654\n",
      "\n",
      "\n",
      "Confusion matrix for validation set\n",
      "                        Predicted Positive Review  Predicted Negative Review\n",
      "Actual Positive Review                        108                        540\n",
      "Actual Negative Review                         65                       1941\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with TF-IDF and Logistic Regression\n",
    "pipe_tvec_lr = Pipeline([\n",
    "    ('tvec', TfidfVectorizer(stop_words='english')),\n",
    "    ('lr', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "pipe_tvec_lr_params = {\n",
    "    'tvec__max_features': [300], #100,200\n",
    "    'tvec__min_df': [2,3], #2,3 \n",
    "    'tvec__max_df': [.9,.95], \n",
    "#     'tvec__ngram_range':[(1,1),(1,2)],  \n",
    "    'lr__penalty': ['l2'],\n",
    "    'lr__C': [.1, 1] #.1, .01\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "gs_tvec_lr = GridSearchCV(pipe_tvec_lr, # Objects to optimise\n",
    "                          param_grid = pipe_tvec_lr_params, # Hyperparameters for tuning\n",
    "                          cv=10) # 10-fold cross validation\n",
    "\n",
    "# Fit model on to training data\n",
    "gs_tvec_lr.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions on validation set\n",
    "tvec_lr_pred = gs_tvec_lr.predict(X_val)\n",
    "\n",
    "# Print best parameters\n",
    "print('Best parameters: ', gs_tvec_lr.best_params_)\n",
    "\n",
    "# Print accuracy scores\n",
    "print('Best CV score: ', gs_tvec_lr.best_score_)\n",
    "print('Training score:', gs_tvec_lr.score(X_train, y_train))\n",
    "print('Validation score:', gs_tvec_lr.score(X_val, y_val))\n",
    "print('')\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "cmat(y_val, tvec_lr_pred, 'validation set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count vectorizer & naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'cvec__max_df': 0.9, 'cvec__max_features': 500, 'cvec__min_df': 2}\n",
      "Best CV score:  0.7689853938028829\n",
      "Training score: 0.7836819295270397\n",
      "Validation score: 0.7607385079125848\n",
      "\n",
      "Classification report for validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.27      0.36       648\n",
      "           1       0.80      0.92      0.85      2006\n",
      "\n",
      "    accuracy                           0.76      2654\n",
      "   macro avg       0.66      0.60      0.61      2654\n",
      "weighted avg       0.73      0.76      0.73      2654\n",
      "\n",
      "\n",
      "Confusion matrix for validation set\n",
      "                        Predicted Positive Review  Predicted Negative Review\n",
      "Actual Positive Review                        178                        470\n",
      "Actual Negative Review                        165                       1841\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with Count Vectorizer and Naive Bayes\n",
    "pipe_cvec_nb = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words='english')),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "pipe_cvec_nb_params = {\n",
    "    'cvec__max_features': [500], #200\n",
    "    'cvec__min_df': [2,3],\n",
    "    'cvec__max_df': [.9,.95], \n",
    "#     'cvec__ngram_range':[(1,1),(1,2)],  \n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "gs_cvec_nb = GridSearchCV(pipe_cvec_nb, # Objects to optimise\n",
    "                          param_grid = pipe_cvec_nb_params, # Hyperparameters for tuning\n",
    "                          cv=10) # 10-fold cross validation\n",
    "\n",
    "# Fit model on to training data\n",
    "gs_cvec_nb.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions on validation set\n",
    "cvec_nb_pred = gs_cvec_nb.predict(X_val)\n",
    "\n",
    "# Print best parameters\n",
    "print('Best parameters: ', gs_cvec_nb.best_params_)\n",
    "\n",
    "# Print accuracy scores\n",
    "print('Best CV score: ', gs_cvec_nb.best_score_)\n",
    "print('Training score:', gs_cvec_nb.score(X_train, y_train))\n",
    "print('Validation score:', gs_cvec_nb.score(X_val, y_val))\n",
    "print('')\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "cmat(y_val, cvec_nb_pred, 'validation set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf & naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'tvec__max_df': 0.9, 'tvec__max_features': 500, 'tvec__min_df': 2}\n",
      "Best CV score:  0.7679487247755111\n",
      "Training score: 0.7704918032786885\n",
      "Validation score: 0.7709118311981914\n",
      "\n",
      "Classification report for validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.07      0.13       648\n",
      "           1       0.77      1.00      0.87      2006\n",
      "\n",
      "    accuracy                           0.77      2654\n",
      "   macro avg       0.82      0.53      0.50      2654\n",
      "weighted avg       0.79      0.77      0.69      2654\n",
      "\n",
      "\n",
      "Confusion matrix for validation set\n",
      "                        Predicted Positive Review  Predicted Negative Review\n",
      "Actual Positive Review                         47                        601\n",
      "Actual Negative Review                          7                       1999\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with TF-IDF and Naive Bayes\n",
    "pipe_tvec_nb = Pipeline([\n",
    "    ('tvec', TfidfVectorizer(stop_words='english')),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "pipe_tvec_nb_params = {\n",
    "    'tvec__max_features': [500], #200\n",
    "    'tvec__min_df': [2,3], #\n",
    "    'tvec__max_df': [.9,.95], \n",
    "#     'tvec__ngram_range':[(1,1),(1,2)],  \n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "gs_tvec_nb = GridSearchCV(pipe_tvec_nb, # Objects to optimise\n",
    "                          param_grid = pipe_tvec_nb_params, # Hyperparameters for tuning\n",
    "                          cv=10) # 10-fold cross validation\n",
    "\n",
    "# Fit model on to training data\n",
    "gs_tvec_nb.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions on validation set\n",
    "tvec_nb_pred = gs_tvec_nb.predict(X_val)\n",
    "\n",
    "# Print best parameters\n",
    "print('Best parameters: ', gs_tvec_nb.best_params_)\n",
    "\n",
    "# Print accuracy scores\n",
    "print('Best CV score: ', gs_tvec_nb.best_score_)\n",
    "print('Training score:', gs_tvec_nb.score(X_train, y_train))\n",
    "print('Validation score:', gs_tvec_nb.score(X_val, y_val))\n",
    "print('')\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "cmat(y_val, tvec_nb_pred, 'validation set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count vectorizer & svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'cvec__max_df': 0.9, 'cvec__max_features': 300, 'cvec__min_df': 2, 'svc__C': 0.1, 'svc__kernel': 'linear'}\n",
      "Best CV score:  0.7701146273192153\n",
      "Training score: 0.7736951196532881\n",
      "Validation score: 0.7656367746797287\n",
      "\n",
      "Classification report for validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.10      0.17       648\n",
      "           1       0.77      0.98      0.86      2006\n",
      "\n",
      "    accuracy                           0.77      2654\n",
      "   macro avg       0.70      0.54      0.52      2654\n",
      "weighted avg       0.74      0.77      0.69      2654\n",
      "\n",
      "\n",
      "Confusion matrix for validation set\n",
      "                        Predicted Positive Review  Predicted Negative Review\n",
      "Actual Positive Review                         64                        584\n",
      "Actual Negative Review                         38                       1968\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with Count Vectorizer and SVC\n",
    "pipe_cvec_svc = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words='english')),\n",
    "    ('svc', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "pipe_cvec_svc_params = {\n",
    "    'cvec__max_features': [300], #200,500\n",
    "    'cvec__min_df': [2,3], \n",
    "    'cvec__max_df': [.9,.95], \n",
    "#     'cvec__ngram_range':[(1,1),(1,2)],  \n",
    "    'svc__kernel': ['linear'], #'poly', 'rbf'\n",
    "#     'svc__degree': [3],\n",
    "    'svc__C': [.1]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "gs_cvec_svc = GridSearchCV(pipe_cvec_svc, # Objects to optimise\n",
    "                          param_grid = pipe_cvec_svc_params, # Hyperparameters for tuning\n",
    "                          cv=10) # 10-fold cross validation\n",
    "\n",
    "# Fit model on to training data\n",
    "gs_cvec_svc.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions on validation set\n",
    "cvec_svc_pred = gs_cvec_svc.predict(X_val)\n",
    "\n",
    "# Print best parameters\n",
    "print('Best parameters: ', gs_cvec_svc.best_params_)\n",
    "\n",
    "# Print accuracy scores\n",
    "print('Best CV score: ', gs_cvec_svc.best_score_)\n",
    "print('Training score:', gs_cvec_svc.score(X_train, y_train))\n",
    "print('Validation score:', gs_cvec_svc.score(X_val, y_val))\n",
    "print('')\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "cmat(y_val, cvec_svc_pred, 'validation set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf & svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'svc__C': 0.1, 'svc__kernel': 'linear', 'tvec__max_df': 0.9, 'tvec__max_features': 800, 'tvec__min_df': 2}\n",
      "Best CV score:  0.7622011178737325\n",
      "Training score: 0.7631430186546071\n",
      "Validation score: 0.7633760361718162\n",
      "\n",
      "Classification report for validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.04      0.07       648\n",
      "           1       0.76      1.00      0.86      2006\n",
      "\n",
      "    accuracy                           0.76      2654\n",
      "   macro avg       0.81      0.52      0.47      2654\n",
      "weighted avg       0.79      0.76      0.67      2654\n",
      "\n",
      "\n",
      "Confusion matrix for validation set\n",
      "                        Predicted Positive Review  Predicted Negative Review\n",
      "Actual Positive Review                         24                        624\n",
      "Actual Negative Review                          4                       2002\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with TF-IDF Vectorizer and SVC\n",
    "pipe_tvec_svc = Pipeline([\n",
    "    ('tvec', TfidfVectorizer(stop_words='english')),\n",
    "    ('svc', SVC(probability=True, random_state=42)) \n",
    "])\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "pipe_tvec_svc_params = {\n",
    "    'tvec__max_features': [800], #200,500\n",
    "    'tvec__min_df': [2,3], \n",
    "    'tvec__max_df': [.9,.95], \n",
    "#     'tvec__ngram_range':[(1,1),(1,2)],  \n",
    "    'svc__kernel': ['linear'], #'poly', 'rbf'\n",
    "#     'svc__degree': [3],\n",
    "    'svc__C': [.1] # .01\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "gs_tvec_svc = GridSearchCV(pipe_tvec_svc, # Objects to optimise\n",
    "                          param_grid = pipe_tvec_svc_params, # Hyperparameters for tuning\n",
    "                          cv=10) # 10-fold cross validation\n",
    "\n",
    "# Fit model on to training data\n",
    "gs_tvec_svc.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions on validation set\n",
    "tvec_svc_pred = gs_tvec_svc.predict(X_val)\n",
    "\n",
    "# Print best parameters\n",
    "print('Best parameters: ', gs_tvec_svc.best_params_)\n",
    "\n",
    "# Print accuracy scores\n",
    "print('Best CV score: ', gs_tvec_svc.best_score_)\n",
    "print('Training score:', gs_tvec_svc.score(X_train, y_train))\n",
    "print('Validation score:', gs_tvec_svc.score(X_val, y_val))\n",
    "print('')\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "cmat(y_val, tvec_svc_pred, 'validation set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.7964009798379499\n",
      "Validation score: 0.7856066314996232\n",
      "\n",
      "Classification report for validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.21      0.33       648\n",
      "           1       0.79      0.97      0.87      2006\n",
      "\n",
      "    accuracy                           0.79      2654\n",
      "   macro avg       0.75      0.59      0.60      2654\n",
      "weighted avg       0.77      0.79      0.74      2654\n",
      "\n",
      "\n",
      "Confusion matrix for validation set\n",
      "                        Predicted Positive Review  Predicted Negative Review\n",
      "Actual Positive Review                        139                        509\n",
      "Actual Negative Review                         60                       1946\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Voting Classifier with TF-IDF Logistic Regression and SVC\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('tvec_lr', gs_tvec_lr),\n",
    "                ('tvec_svc', gs_tvec_svc)], \n",
    "    voting='soft', \n",
    "    weights=[1,2]\n",
    ")\n",
    "\n",
    "# Fit model on to training data\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions on validation set\n",
    "voting_pred = voting_clf.predict(X_val)\n",
    "\n",
    "# Print accuracy scores\n",
    "print('Training score:', voting_clf.score(X_train, y_train))\n",
    "print('Validation score:', voting_clf.score(X_val, y_val))\n",
    "print('')\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "cmat(y_val, voting_pred, 'validation set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = X_train.values\n",
    "X_val_list = X_val.values\n",
    "\n",
    "y_train_list = y_train.values\n",
    "y_val_list = y_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000 # Note: Model tends to overfit when max_words is set to 2000-3000 words\n",
    "\n",
    "# Tokenize the data\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(list(X_train_list))\n",
    "\n",
    "# Convert the text to sequences\n",
    "X_train_list = tokenizer.texts_to_sequences(X_train_list)\n",
    "X_val_list = tokenizer.texts_to_sequences(X_val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 17298\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index)+1\n",
    "print('Vocabulary size:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 30 \n",
    "\n",
    "X_train_padded = pad_sequences(X_train_list, maxlen=max_length, padding='post')\n",
    "X_val_padded = pad_sequences(X_val_list, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kkc3\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\kkc3\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\kkc3\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\kkc3\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\kkc3\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\kkc3\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model\n",
    "model = Sequential()\n",
    "\n",
    "# Add embedding layer, embed_dim:8\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length)) \n",
    "\n",
    "# SpatialDropout1D performs variational dropout\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "\n",
    "# Add LSTM\n",
    "model.add(Bidirectional(LSTM(8, return_sequences=True, dropout=0.5, recurrent_dropout=0))) \n",
    "\n",
    "# Add a dense layer\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 30, 8)             138384    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 30, 8)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 30, 16)            1088      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 30, 8)             136       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30, 1)             9         \n",
      "=================================================================\n",
      "Total params: 139,617\n",
      "Trainable params: 139,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callback to save the models and weights\n",
    "\n",
    "outputFolder = './GA Capstone CMON/output'\n",
    "if not os.path.exists(outputFolder):\n",
    "    os.makedirs(outputFolder)\n",
    "filepath = outputFolder+\"/model-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath, monitor='val_accuracy', verbose=1,\n",
    "    save_best_only=False, save_weights_only=False,\n",
    "    save_frequency=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (10614, 1) was passed for an output of shape (None, 30, 1) while using as loss `binary_crossentropy`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    707\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         shuffle=shuffle)\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2690\u001b[0m           \u001b[1;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2691\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[1;32m-> 2692\u001b[1;33m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[0;32m   2693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m       \u001b[1;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[1;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[0;32m    547\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[0;32m    548\u001b[0m                            \u001b[1;34m' was passed for an output of shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                            \u001b[1;34m' while using as loss `'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m                            \u001b[1;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m                            'as the output.')\n",
      "\u001b[1;31mValueError\u001b[0m: A target array with shape (10614, 1) was passed for an output of shape (None, 30, 1) while using as loss `binary_crossentropy`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit the model and store it in the history object\n",
    "history = model.fit(X_train_padded, y_train_list, epochs=10, batch_size=64, validation_data=(X_val_padded, y_val_list), callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-abc58c1041e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Validation loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training and Validation Loss by Epoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bold'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the training and validation loss by epoch\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "epochs = range(1,11)\n",
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], label='Validation loss')\n",
    "plt.title('Training and Validation Loss by Epoch', size=15, weight='bold')\n",
    "plt.xlabel('Epochs', size=12)\n",
    "plt.ylabel('Loss', size=12)\n",
    "plt.xticks(np.arange(1,11,1))\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy by epoch\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "epochs = range(1,11)\n",
    "plt.plot(epochs, history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(epochs, history.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy by Epoch', size=15, weight='bold')\n",
    "plt.xlabel('Epochs', size=12)\n",
    "plt.ylabel('Accuracy', size=12)\n",
    "plt.xticks(np.arange(1,11,1))\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a check-pointed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights\n",
    "model.load_weights('./output/model-08-0.80.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on validation set\n",
    "class_preds = (model.predict(X_val_padded) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = []\n",
    "\n",
    "# Loop through the class prediction list and append the predictions to val_preds\n",
    "for i in class_preds:\n",
    "    val_preds.append(i[0][0])\n",
    "\n",
    "# Convert val_preds to a series\n",
    "val_preds = pd.Series(val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy scores\n",
    "print('Accuracy score on training set: ', model.evaluate(X_train_padded, y_train_list, verbose=0)[1])\n",
    "print('Accuracy score on validation set: ', model.evaluate(X_val_padded, y_val_list, verbose=0)[1])\n",
    "print('')\n",
    "\n",
    "# Print classification report and confusion matrix for validation set\n",
    "cmat(y_val, val_preds, 'validation set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
