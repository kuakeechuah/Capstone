{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone: Sentiment Analysis for CMON\n",
    "## Data Cleaning, Pre-processing and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CMON is a listed company on the HK stock Exchange that sells it's boardgames through a suite of online platforms. It brings boardgames to live by Kickstarter funding and boardgames would go into production once the funding quota is met.\n",
    "\n",
    "In order to come up with games that are appealing to consumers, it is imperative for CMON to identify customer sentiments, their likes and dislikes and painpoints.\n",
    "\n",
    "For phase 1 of this project, the data science team has been tasked to classify positive and negative reviews on Boardgamegeeks.com for all of CMON's games using Natural Language Procesisng (NLP).\n",
    "\n",
    "The model that achieves the highest accuracy and recall on the validation set would be selected for production. The team would also be identifying the key contributors for the classifications.\n",
    "\n",
    "For phase 2 of the project, the team would be looking at building a recommeder system for CMON based on ratings of the board games.\n",
    "\n",
    "Phase 1 is crucial for the chief creative director so that CMON is able to understand what consumers like or dislike in their board games so that resources can be channeled to ensuring that the games they launch on kickstarter can be fully and hopefully over subscribed.\n",
    "\n",
    "Phase 2 would enhance their company's sales by recommending games that players enjoy to encourage purchase.\n",
    "\n",
    "Deadline for phase 1 would be by the beginning of August 2020 and phase 2 rollout would be dependent on the successful completion of phase 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data has been scapped from https://boardgamegeek.com/ for all CMON games. Script is used to scrape all the ratings and comments for all CMON boardgames and saved into CSV format. There are 4 columns including the index.\n",
    "Other columns include the username ( registered user name for the forum), ratings given by user for the boardgame (from 1 to 10) and comments from the user.\n",
    "\n",
    "Ratings from 5 and below would be deemed to be negative, ratings from 6 to 10 would be deemed to be positive.\n",
    "\n",
    "There is one csv for each board games and the data would be compiled for review. Preliminary assessment indicates that there would be approximately 16K rows.\n",
    "\n",
    "They would be split into 50% (train-test) set and 50% holdout set.\n",
    "\n",
    "The comments column would be lemmatize/ tokenised into useful words.\n",
    "\n",
    "Data cleaning:\n",
    "\n",
    "Remove duplicated reviews\n",
    "Remove reviews that do not have any meaningful words\n",
    "Remove reviews that are non-English or gibberish\n",
    "Pre-processing:\n",
    "\n",
    "Remove HTML tags\n",
    "Use regular expression to remove special characters and numbers\n",
    "Lowercase words\n",
    "Use NLTK to remove stopwords\n",
    "Remove common occurring words that appear in both positive and negative sentiments\n",
    "Use NLTK to stem words to their root form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA would be performed on the the comments.\n",
    "\n",
    "1. Wordcloud to visualise keywords\n",
    "2. Count to visualise keywords\n",
    "3. Plot to identify distribution of valuable words\n",
    "\n",
    "etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_rows', None)\n",
    "\n",
    "import regex as re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from os import path\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Ankh Gods of Egypt comments csv into a dataframe\n",
    "ankh = pd.read_csv('../GA Capstone CMON/datasets/Ankh Gods of Egypt comments.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Arcadia Quest comments csv into a dataframe\n",
    "arcadia = pd.read_csv('../GA Capstone CMON/datasets/Arcadia Quest comments.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Blood Rage comments csv into a dataframe\n",
    "rage = pd.read_csv('../GA Capstone CMON/datasets/Blood Rage comments.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Bloodborne The Board Game comments csv into a dataframe\n",
    "borne = pd.read_csv('../GA Capstone CMON/datasets/Bloodborne The Board Game comments.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Blue Moon City comments csv into a dataframe\n",
    "blue = pd.read_csv('../GA Capstone CMON/datasets/Blue Moon City comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Chyba comments csv into a dataframe\n",
    "chyba = pd.read_csv('../GA Capstone CMON/datasets/Chyba comments.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Cthulhu Death May Die comments csv into a dataframe\n",
    "may = pd.read_csv('../GA Capstone CMON/datasets/Cthulhu Death May Die comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import de hielo y fuego El juego de miniaturas comments csv into a dataframe\n",
    "miniaturas = pd.read_csv('../GA Capstone CMON/datasets/de hielo y fuego El juego de miniaturas comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Duckomenta Art comments csv into a dataframe\n",
    "art = pd.read_csv('../GA Capstone CMON/datasets/Duckomenta Art comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Ethnos comments comments csv into a dataframe\n",
    "ethnos = pd.read_csv('../GA Capstone CMON/datasets/Ethnos comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Foodies comments comments csv into a dataframe\n",
    "food = pd.read_csv('../GA Capstone CMON/datasets/Foodies comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Genios Victorianos comments csv into a dataframe\n",
    "victoria = pd.read_csv('../GA Capstone CMON/datasets/Genios Victorianos comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gizmos comments csv into a dataframe\n",
    "gizmos = pd.read_csv('../GA Capstone CMON/datasets/Gizmos comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import God of War Das Kartenspiel comments csv into a dataframe\n",
    "war = pd.read_csv('../GA Capstone CMON/datasets/God of War Das Kartenspiel comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Ha Ver A comments csv into a dataframe\n",
    "haver = pd.read_csv('../GA Capstone CMON/datasets/Ha Ver A comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import HATE comments csv into a dataframe\n",
    "hate = pd.read_csv('../GA Capstone CMON/datasets/HATE comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Los Autos Locos El Juego de Mesa comments csv into a dataframe\n",
    "los = pd.read_csv('../GA Capstone CMON/datasets/Ha Ver A comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Marvel United comments csv into a dataframe\n",
    "marvel = pd.read_csv('../GA Capstone CMON/datasets/Marvel United comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Massive Darkness comments csv into a dataframe\n",
    "massive = pd.read_csv('../GA Capstone CMON/datasets/Massive Darkness comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Moloch comments csv into a dataframe\n",
    "moloch = pd.read_csv('../GA Capstone CMON/datasets/Moloch comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Munchkin Dungeon comments csv into a dataframe\n",
    "munchkin = pd.read_csv('../GA Capstone CMON/datasets/Munchkin Dungeon comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Nap comments csv into a dataframe\n",
    "nap = pd.read_csv('../GA Capstone CMON/datasets/Nap comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Narcos hra comments into a dataframe\n",
    "narcos = pd.read_csv('../GA Capstone CMON/datasets/Narcos hra comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Project ELITE comments csv into a dataframe\n",
    "project = pd.read_csv('../GA Capstone CMON/datasets/Project ELITE comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Sheriff of Nottingham Edition comments csv into a dataframe\n",
    "sheriff = pd.read_csv('../GA Capstone CMON/datasets/Sheriff of Nottingham Edition comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Starcadia Quest comments csv into a dataframe\n",
    "starcadia = pd.read_csv('../GA Capstone CMON/datasets/Starcadia Quest comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Sugar Blast comments csv into a dataframe\n",
    "sugar = pd.read_csv('../GA Capstone CMON/datasets/Sugar Blast comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import The Grizzled comments csv into a dataframe\n",
    "grizzled = pd.read_csv('../GA Capstone CMON/datasets/The Grizzled comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Trudvang Legends comments csv into a dataframe\n",
    "legends = pd.read_csv('../GA Capstone CMON/datasets/Trudvang Legends comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Wrath of Kings comments csv into a dataframe\n",
    "wrath = pd.read_csv('../GA Capstone CMON/datasets/Wrath of Kings comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Zombicide comments csv into a dataframe\n",
    "zombie = pd.read_csv('../GA Capstone CMON/datasets/Zombicide comments.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined all dataframes into one\n",
    "df = pd.concat([ankh, arcadia, rage, borne, blue, chyba, may, miniaturas, art,\n",
    "                ethnos, food, victoria,gizmos, war, haver, hate, los, marvel,\n",
    "                massive, moloch, munchkin, nap, narcos, project, sheriff,\n",
    "                starcadia, sugar, grizzled, legends, wrath, zombie])\n",
    "# Reindex the new dataframe\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23089, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>username</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23084</th>\n",
       "      <td>2528</td>\n",
       "      <td>Zyrallus</td>\n",
       "      <td>3.8</td>\n",
       "      <td>So much potential here. Seriously, with a less...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23085</th>\n",
       "      <td>2529</td>\n",
       "      <td>zyx0xyz</td>\n",
       "      <td>7.6</td>\n",
       "      <td>唯一的亮点就是模型和版图美工了，但本人作为一个十多年的生化危机fans，体验zombicid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23086</th>\n",
       "      <td>2530</td>\n",
       "      <td>zzool73</td>\n",
       "      <td>8.0</td>\n",
       "      <td>If you are creative there are a lot of house r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23087</th>\n",
       "      <td>2531</td>\n",
       "      <td>_ph_</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Still playing a lot of the game with friends, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23088</th>\n",
       "      <td>2532</td>\n",
       "      <td>_The_Inquiry_</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Prior to 2020: 1 play\\n\\nIf there's a single g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       username  rating  \\\n",
       "23084        2528       Zyrallus     3.8   \n",
       "23085        2529        zyx0xyz     7.6   \n",
       "23086        2530        zzool73     8.0   \n",
       "23087        2531           _ph_     9.0   \n",
       "23088        2532  _The_Inquiry_     4.0   \n",
       "\n",
       "                                                 comment  \n",
       "23084  So much potential here. Seriously, with a less...  \n",
       "23085  唯一的亮点就是模型和版图美工了，但本人作为一个十多年的生化危机fans，体验zombicid...  \n",
       "23086  If you are creative there are a lot of house r...  \n",
       "23087  Still playing a lot of the game with friends, ...  \n",
       "23088  Prior to 2020: 1 play\\n\\nIf there's a single g...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the data has been re-indexed\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop selftext duplicates as we only want unique posts\n",
    "df.drop_duplicates('comment', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21156, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0       0\n",
       "username         0\n",
       "rating        4786\n",
       "comment          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values in iphonehelp\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21156 entries, 0 to 23088\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  21156 non-null  int64  \n",
      " 1   username    21156 non-null  object \n",
      " 2   rating      16370 non-null  float64\n",
      " 3   comment     21155 non-null  object \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 826.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing would enable transformation of our text into a more digestible form so that our classifier can perform better. The steps taken is as follows:\n",
    "\n",
    "- 1. Remove html tags using beautifulsoup\n",
    "- 2. Lowercase all words and split word up\n",
    "- 3. Remove non-letters: Remove special characters and numbers\n",
    "- 4. Remove keywords that points to a speciic subreddit\n",
    "- 5. Remove stopwords: These are common words that are not useful for text classification\n",
    "- 6. Lemmatize words: This will convert each word to its base form\n",
    "- 7. Finally, rejoin words back into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove bs4 warnings as scrapping includes pinned moderator posts with many url links and pictures\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to convert text to a string of meaningful words\n",
    "def meaningful_text(self_text):\n",
    "    \n",
    "    # 1. Remove html tags\n",
    "    words = BeautifulSoup(self_text).get_text()\n",
    "    \n",
    "    # 2. Convert words to lower case and split each word up\n",
    "    words = self_text.lower()\n",
    "    \n",
    "    # iphon likely to be spelling error for iphone, removing it as we do not want iphone inside too\n",
    "    #words = words.replace('iphon', '') \n",
    "    \n",
    "    # 3. Remove non-letters\n",
    "    words = re.sub(\"[^a-zA-Z]\", \" \", words).split()    \n",
    "    \n",
    "    #Searching through a set is faster than searching through a list,so we will convert stopwords to a set\n",
    "    stops = set(stopwords.words('english'))\n",
    "    \n",
    "    # 4. Add certain keywords to stopwords as its too obvious for which reddit\n",
    "    #stops.update(['Android','Iphone','android','iphon','phone','http','www','com', 'Iphon','IPHON'])\n",
    "    \n",
    "    # 5. Remove stopwords\n",
    "    meaningful_words = [w for w in words if w not in stops]\n",
    "    \n",
    "    # 6. Lemmatize words\n",
    "    meaningful_words = [lemmatizer.lemmatize(w) for w in meaningful_words]\n",
    "   \n",
    "    # 7. Join words back into one string, with a space in between each word\n",
    "    return(\" \".join(meaningful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-0338e54d5950>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Creating clean selftext and clean title, and store them in new columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'comment_clean'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'comment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeaningful_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   3628\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3629\u001b[0m         \"\"\"\n\u001b[1;32m-> 3630\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3631\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_map_values\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[1;31m# mapper is a function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-be26be238072>\u001b[0m in \u001b[0;36mmeaningful_text\u001b[1;34m(self_text)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# 1. Remove html tags\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# 2. Convert words to lower case and split each word up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'read'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m        \u001b[1;31m# It's a file-type object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[0mmarkup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m         elif len(markup) <= 256 and (\n\u001b[0m\u001b[0;32m    288\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;34mb'<'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;34m'<'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "# Creating clean selftext and clean title, and store them in new columns\n",
    "df['comment_clean'] = df['comment'].map(meaningful_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
